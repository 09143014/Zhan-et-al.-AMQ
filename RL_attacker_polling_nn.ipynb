{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb84cd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_30608\\1865226673.py:105: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  out = float(h2 @ self.W3 + self.b3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import heapq\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class Event:\n",
    "    def __init__(self, event_type, time, queue_id=None, job_id=None):\n",
    "        self.event_type = event_type\n",
    "        self.time = time\n",
    "        self.queue_id = queue_id\n",
    "        self.job_id = job_id\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.time < other.time\n",
    "\n",
    "\n",
    "class Queue:\n",
    "    def __init__(self, arrival_rate, ini_jobs):\n",
    "        self.queue = deque()\n",
    "        self.arrival_rate = arrival_rate\n",
    "        self.ini_jobs = ini_jobs\n",
    "        self.total_jobs = 0\n",
    "        self.completed_jobs = 0\n",
    "        self.total_wait_time = 0\n",
    "        self.last_queue_length = 0\n",
    "        self.last_time = 0\n",
    "        self.total_queue_length_time = 0\n",
    "\n",
    "    def add_job(self, arrival_time):\n",
    "        job_id = self.total_jobs\n",
    "        self.queue.append((job_id, arrival_time))\n",
    "        self.total_jobs += 1\n",
    "        return job_id\n",
    "\n",
    "    def process_job(self, current_time):\n",
    "        if not self.queue:\n",
    "            return None, 0, None\n",
    "        job_id, arrival_time = self.queue.popleft()\n",
    "        wait_time = current_time - arrival_time\n",
    "        self.completed_jobs += 1\n",
    "        self.total_wait_time += wait_time\n",
    "        return job_id, wait_time, arrival_time\n",
    "\n",
    "    def update_queue_stats(self, current_time):\n",
    "        duration = current_time - self.last_time\n",
    "        self.total_queue_length_time += self.last_queue_length * duration\n",
    "        self.last_queue_length = len(self.queue)\n",
    "        self.last_time = current_time\n",
    "\n",
    "\n",
    "class Server:\n",
    "    def __init__(self, service_rate, switch_time):\n",
    "        self.service_rate = service_rate\n",
    "        self.switch_time = switch_time\n",
    "        self.state = 'idle'  # 'idle' / 'serving' / 'switching'\n",
    "        self.current_queue = None\n",
    "        self.current_job_id = None\n",
    "        self.current_job_arrival_time = None\n",
    "        self.last_state_change_time = 0.0\n",
    "        self.total_busy_time = 0.0\n",
    "\n",
    "    def update_utilization(self, current_time):\n",
    "        duration = current_time - self.last_state_change_time\n",
    "        if self.state in ['serving', 'switching']:\n",
    "            self.total_busy_time += duration\n",
    "        self.last_state_change_time = current_time\n",
    "\n",
    "class QNetwork:\n",
    "    \"\"\"Two-hidden-layer ReLU MLP used to approximate Q(X, a, b).\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dims=(64, 32), seed=0, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        self.W1 = self.rng.normal(scale=0.1, size=(input_dim, hidden_dims[0]))\n",
    "        self.b1 = np.zeros(hidden_dims[0])\n",
    "        self.W2 = self.rng.normal(scale=0.1, size=(hidden_dims[0], hidden_dims[1]))\n",
    "        self.b2 = np.zeros(hidden_dims[1])\n",
    "        self.W3 = self.rng.normal(scale=0.1, size=(hidden_dims[1], 1))\n",
    "        self.b3 = np.zeros(1)\n",
    "\n",
    "        # Adam parameters\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.m_W1 = np.zeros_like(self.W1)\n",
    "        self.m_b1 = np.zeros_like(self.b1)\n",
    "        self.m_W2 = np.zeros_like(self.W2)\n",
    "        self.m_b2 = np.zeros_like(self.b2)\n",
    "        self.m_W3 = np.zeros_like(self.W3)\n",
    "        self.m_b3 = np.zeros_like(self.b3)\n",
    "        self.v_W1 = np.zeros_like(self.W1)\n",
    "        self.v_b1 = np.zeros_like(self.b1)\n",
    "        self.v_W2 = np.zeros_like(self.W2)\n",
    "        self.v_b2 = np.zeros_like(self.b2)\n",
    "        self.v_W3 = np.zeros_like(self.W3)\n",
    "        self.v_b3 = np.zeros_like(self.b3)\n",
    "\n",
    "        # Time step counter for bias correction\n",
    "        self.t = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        z1 = x @ self.W1 + self.b1\n",
    "        h1 = np.maximum(0.0, z1)\n",
    "        z2 = h1 @ self.W2 + self.b2\n",
    "        h2 = np.maximum(0.0, z2)\n",
    "        out = float(h2 @ self.W3 + self.b3)\n",
    "        cache = (x, z1, h1, z2, h2)\n",
    "        return out, cache\n",
    "\n",
    "    def predict(self, x):\n",
    "        out, _ = self.forward(x)\n",
    "        return out\n",
    "\n",
    "    def params_vector(self):\n",
    "        return np.concatenate([ \n",
    "            self.W1.ravel(), self.b1.ravel(), \n",
    "            self.W2.ravel(), self.b2.ravel(),\n",
    "            self.W3.ravel(), self.b3.ravel()\n",
    "        ])\n",
    "\n",
    "    def train(self, x, target, eta, clip=None):\n",
    "        self.t += 1  # Increment time step\n",
    "        q_pred, (x, z1, h1, z2, h2) = self.forward(x)\n",
    "        error = q_pred - target  # dL/dq for 0.5*(q-target)^2\n",
    "\n",
    "        # Gradients\n",
    "        grad_W3 = np.outer(h2, error)\n",
    "        grad_b3 = np.array([error])\n",
    "        grad_h2 = self.W3.flatten() * error\n",
    "        grad_z2 = grad_h2 * (z2 > 0)\n",
    "        grad_W2 = np.outer(h1, grad_z2)\n",
    "        grad_b2 = grad_z2\n",
    "        grad_h1 = grad_z2 @ self.W2.T\n",
    "        grad_z1 = grad_h1 * (z1 > 0)\n",
    "        grad_W1 = np.outer(x, grad_z1)\n",
    "        grad_b1 = grad_z1\n",
    "\n",
    "        grads = [grad_W1, grad_b1, grad_W2, grad_b2, grad_W3, grad_b3]\n",
    "\n",
    "        # Adam updates\n",
    "        for i, grad in enumerate(grads):\n",
    "            # m_t and v_t update for Adam\n",
    "            if i == 0:\n",
    "                self.m_W1 = self.beta1 * self.m_W1 + (1 - self.beta1) * grad\n",
    "                self.v_W1 = self.beta2 * self.v_W1 + (1 - self.beta2) * grad**2\n",
    "            elif i == 1:\n",
    "                self.m_b1 = self.beta1 * self.m_b1 + (1 - self.beta1) * grad\n",
    "                self.v_b1 = self.beta2 * self.v_b1 + (1 - self.beta2) * grad**2\n",
    "            elif i == 2:\n",
    "                self.m_W2 = self.beta1 * self.m_W2 + (1 - self.beta1) * grad\n",
    "                self.v_W2 = self.beta2 * self.v_W2 + (1 - self.beta2) * grad**2\n",
    "            elif i == 3:\n",
    "                self.m_b2 = self.beta1 * self.m_b2 + (1 - self.beta1) * grad\n",
    "                self.v_b2 = self.beta2 * self.v_b2 + (1 - self.beta2) * grad**2\n",
    "            elif i == 4:\n",
    "                self.m_W3 = self.beta1 * self.m_W3 + (1 - self.beta1) * grad\n",
    "                self.v_W3 = self.beta2 * self.v_W3 + (1 - self.beta2) * grad**2\n",
    "            elif i == 5:\n",
    "                self.m_b3 = self.beta1 * self.m_b3 + (1 - self.beta1) * grad\n",
    "                self.v_b3 = self.beta2 * self.v_b3 + (1 - self.beta2) * grad**2\n",
    "\n",
    "        # Bias correction\n",
    "        m_W1_hat = self.m_W1 / (1 - self.beta1**self.t)\n",
    "        v_W1_hat = self.v_W1 / (1 - self.beta2**self.t)\n",
    "        m_b1_hat = self.m_b1 / (1 - self.beta1**self.t)\n",
    "        v_b1_hat = self.v_b1 / (1 - self.beta2**self.t)\n",
    "        m_W2_hat = self.m_W2 / (1 - self.beta1**self.t)\n",
    "        v_W2_hat = self.v_W2 / (1 - self.beta2**self.t)\n",
    "        m_b2_hat = self.m_b2 / (1 - self.beta1**self.t)\n",
    "        v_b2_hat = self.v_b2 / (1 - self.beta2**self.t)\n",
    "        m_W3_hat = self.m_W3 / (1 - self.beta1**self.t)\n",
    "        v_W3_hat = self.v_W3 / (1 - self.beta2**self.t)\n",
    "        m_b3_hat = self.m_b3 / (1 - self.beta1**self.t)\n",
    "        v_b3_hat = self.v_b3 / (1 - self.beta2**self.t)\n",
    "\n",
    "        # Update parameters with Adam\n",
    "        self.W1 -= eta * m_W1_hat / (np.sqrt(v_W1_hat) + self.epsilon)\n",
    "        self.b1 -= eta * m_b1_hat / (np.sqrt(v_b1_hat) + self.epsilon)\n",
    "        self.W2 -= eta * m_W2_hat / (np.sqrt(v_W2_hat) + self.epsilon)\n",
    "        self.b2 -= eta * m_b2_hat / (np.sqrt(v_b2_hat) + self.epsilon)\n",
    "        self.W3 -= eta * m_W3_hat / (np.sqrt(v_W3_hat) + self.epsilon)\n",
    "        self.b3 -= eta * m_b3_hat / (np.sqrt(v_b3_hat) + self.epsilon)\n",
    "\n",
    "        delta = target - q_pred\n",
    "        return delta, q_pred\n",
    "\n",
    "\n",
    "class PollingSystem:\n",
    "    def __init__(self, queue_nums, arrival_rates, ini_jobs_list,\n",
    "                 service_rate, switch_time, simulation_time):\n",
    "        self.queue_nums = queue_nums\n",
    "        self.queues = [Queue(arrival_rates[i], ini_jobs_list[i]) for i in range(queue_nums)]\n",
    "        self.server = Server(service_rate, switch_time)\n",
    "        self.event_queue = []\n",
    "        self.current_time = 0.0\n",
    "        self.simulation_time = simulation_time\n",
    "        self.job_counter = 0\n",
    "\n",
    "        # === AMQ / RL ?? ===\n",
    "        self.gamma = 0.9\n",
    "        self.eta0 = 0.01\n",
    "        self.step_counter = 0\n",
    "        self.cost_attack = 8.0\n",
    "        self.cost_defend = 6.0\n",
    "        self.switch_cost_val = 1.0\n",
    "        self.delta_clip = 50.0\n",
    "        self.step_clip = 1e3\n",
    "        self.train_interval = 1\n",
    "\n",
    "        # === nonlinear Q approximator ===\n",
    "        # ????????? 5 ? [1, x_i + d_i, (x_i + d_i)^2, a, b]\n",
    "        self.input_dim = 5 * queue_nums\n",
    "        self.q_net = QNetwork(self.input_dim, hidden_dims=(128, 64), seed=42)\n",
    "\n",
    "        self.rl_history = []\n",
    "        self.queue_length_records = []\n",
    "\n",
    "        self.schedule_initial_events()\n",
    "\n",
    "    def schedule_initial_events(self):\n",
    "        initial_lengths = [len(q.queue) for q in self.queues]\n",
    "        self.queue_length_records.append((self.current_time, initial_lengths))\n",
    "        for qi, q in enumerate(self.queues):\n",
    "            for _ in range(q.ini_jobs):\n",
    "                q.add_job(self.current_time)\n",
    "                self.job_counter += 1\n",
    "        for i, queue in enumerate(self.queues):\n",
    "            self.schedule_arrival(i)\n",
    "\n",
    "    def record_queue_lengths(self):\n",
    "        current_lengths = [len(q.queue) for q in self.queues]\n",
    "        self.queue_length_records.append((self.current_time, current_lengths))\n",
    "\n",
    "    def schedule_event(self, event):\n",
    "        heapq.heappush(self.event_queue, event)\n",
    "\n",
    "    def schedule_arrival(self, queue_id):\n",
    "        rate = self.queues[queue_id].arrival_rate\n",
    "        if rate <= 0:\n",
    "            return\n",
    "        inter_arrival = np.random.exponential(1.0 / rate)\n",
    "        event_time = self.current_time + inter_arrival\n",
    "        if event_time <= self.simulation_time:\n",
    "            event = Event('arrival', event_time, queue_id)\n",
    "            self.schedule_event(event)\n",
    "\n",
    "    def schedule_service_completion(self, queue_id):\n",
    "        service_time = np.random.exponential(1.0 / self.server.service_rate)\n",
    "        event_time = self.current_time + service_time\n",
    "        event = Event('service_completion', event_time, queue_id, self.server.current_job_id)\n",
    "        self.schedule_event(event)\n",
    "\n",
    "    def schedule_switch_completion(self, queue_id):\n",
    "        event_time = self.current_time + self.server.switch_time\n",
    "        event = Event('switch_completion', event_time, queue_id)\n",
    "        self.schedule_event(event)\n",
    "\n",
    "    def get_longest_queue(self):\n",
    "        queue_lengths = [(len(queue.queue), i) for i, queue in enumerate(self.queues)]\n",
    "        queue_lengths.sort(key=lambda x: (-x[0], x[1]))\n",
    "        return queue_lengths[0][1] if queue_lengths and queue_lengths[0][0] > 0 else None\n",
    "\n",
    "    def get_shortest_queue(self):\n",
    "        queue_lengths = [(len(queue.queue), i) for i, queue in enumerate(self.queues)]\n",
    "        queue_lengths.sort(key=lambda x: (x[0], x[1]))\n",
    "        return queue_lengths[0][1] if queue_lengths and queue_lengths[0][0] >= 0 else None\n",
    "\n",
    "    def compute_reward(self, X, a, b, ns=1.0):\n",
    "        n = len(X)\n",
    "        sx = float(sum(X))\n",
    "        sxx = float(sum(x * x for x in X))\n",
    "        if sxx > 0.0 and n > 0:\n",
    "            fairness = (sx * sx) / (n * sxx)\n",
    "        else:\n",
    "            fairness = 0.0\n",
    "\n",
    "        switch_cost = self.switch_cost_val * float(ns)\n",
    "        cost_a = self.cost_attack * float(a)\n",
    "        cost_b = self.cost_defend * float(b)\n",
    "\n",
    "        return fairness - switch_cost - cost_a + cost_b\n",
    "\n",
    "    def features(self, X, a, b):\n",
    "        n = self.queue_nums\n",
    "        xi = np.asarray(X, dtype=float)\n",
    "        if n == 0:\n",
    "            return np.zeros(0, dtype=float)\n",
    "\n",
    "        max_val = np.max(xi)\n",
    "        min_val = np.min(xi)\n",
    "        idx_max = [i for i in range(n) if xi[i] == max_val]\n",
    "        idx_min = [i for i in range(n) if xi[i] == min_val]\n",
    "\n",
    "        feats = []\n",
    "        for i in range(n):\n",
    "            di = 0.0\n",
    "            if (a == 1 and b == 0 and i in idx_max) or ((a, b) != (1, 0) and i in idx_min):\n",
    "                di = 1.0\n",
    "            val = xi[i] + di\n",
    "            feats.extend([\n",
    "                1.0,\n",
    "                val,\n",
    "                val*val,\n",
    "                float(a),\n",
    "                float(b),\n",
    "            ])\n",
    "        return np.array(feats, dtype=float)\n",
    "\n",
    "    def q_value(self, X, a, b):\n",
    "        phi = self.features(X, a, b)\n",
    "        return float(self.q_net.predict(phi))\n",
    "\n",
    "    def solve_theta_minimax(self, Q_next):\n",
    "        best_c = float('inf')\n",
    "        best_t = 0.0\n",
    "        for t in np.linspace(0.0, 1.0, 201):\n",
    "            th0, th1 = 1.0 - t, t\n",
    "            f0 = th0 * Q_next[(0, 0)] + th1 * Q_next[(0, 1)]\n",
    "            f1 = th0 * Q_next[(1, 0)] + th1 * Q_next[(1, 1)]\n",
    "            c = max(f0, f1)\n",
    "            if c < best_c:\n",
    "                best_c, best_t = c, t\n",
    "        return best_c, {0: 1.0 - best_t, 1: best_t}\n",
    "\n",
    "    def run_simulation(self):\n",
    "        while self.event_queue:\n",
    "            event = heapq.heappop(self.event_queue)\n",
    "            self.current_time = event.time\n",
    "            if self.current_time > self.simulation_time:\n",
    "                break\n",
    "\n",
    "            if event.event_type == 'arrival':\n",
    "                self.process_arrival(event.queue_id)\n",
    "            elif event.event_type == 'service_completion':\n",
    "                self.process_service_completion(event.queue_id, event.job_id)\n",
    "                self.maybe_attack_defend()\n",
    "            elif event.event_type == 'switch_completion':\n",
    "                self.process_switch_completion(event.queue_id)\n",
    "\n",
    "        for queue in self.queues:\n",
    "            queue.update_queue_stats(self.simulation_time)\n",
    "        self.server.update_utilization(self.simulation_time)\n",
    "\n",
    "    def sample_actions_from_behavior(self, X):\n",
    "        l1 = float(sum(X))\n",
    "        p_attack = np.exp(-l1 / 2.0)\n",
    "        a = 1 if np.random.rand() < p_attack else 0\n",
    "\n",
    "        if l1 != 0.0:\n",
    "            p_defend = 1.0 - np.exp(-l1 / 2.0)\n",
    "        else:\n",
    "            p_defend = 0.5\n",
    "        b = 1 if np.random.rand() < p_defend else 0\n",
    "        return a, b\n",
    "\n",
    "    def maybe_attack_defend(self):\n",
    "        X_k = [len(q.queue) for q in self.queues]\n",
    "        a, b = self.sample_actions_from_behavior(X_k)\n",
    "\n",
    "        attack_success = (a == 1 and b == 0 and self.server.state == 'serving')\n",
    "\n",
    "        R_k1 = self.compute_reward(X_k, a, b, ns=1.0)\n",
    "\n",
    "        if attack_success:\n",
    "            self.perform_attack()\n",
    "\n",
    "        X_k1 = [len(q.queue) for q in self.queues]\n",
    "\n",
    "        Q_next = {(aa, bb): self.q_value(X_k1, aa, bb)\n",
    "                  for aa in (0, 1) for bb in (0, 1)}\n",
    "        c_star, theta = self.solve_theta_minimax(Q_next)\n",
    "\n",
    "        q_curr = self.q_value(X_k, a, b)\n",
    "        raw_target = R_k1 + self.gamma * c_star\n",
    "        delta_raw = raw_target - q_curr\n",
    "        if not np.isfinite(delta_raw):\n",
    "            delta_raw = 0.0\n",
    "        delta_k = float(np.clip(delta_raw, -self.delta_clip, self.delta_clip))\n",
    "        target = q_curr + delta_k\n",
    "\n",
    "        phi = self.features(X_k, a, b)\n",
    "\n",
    "        self.step_counter += 1\n",
    "        K = 50000.0\n",
    "        eta_k = self.eta0 / (1.0 + self.step_counter / K)\n",
    "\n",
    "        if (self.step_counter % self.train_interval) == 0:\n",
    "            _, q_before = self.q_net.train(phi, target, eta=eta_k, clip=self.step_clip)\n",
    "            q_after = self.q_net.predict(phi)\n",
    "        else:\n",
    "            q_before = q_after = q_curr\n",
    "\n",
    "        self.rl_history.append({\n",
    "            \"time\": self.current_time,\n",
    "            \"X_k\": X_k,\n",
    "            \"a\": a,\n",
    "            \"b\": b,\n",
    "            \"X_k1\": X_k1,\n",
    "            \"R_k1\": R_k1,\n",
    "            \"delta_raw\": float(delta_raw),\n",
    "            \"delta_clipped\": float(delta_k),\n",
    "            \"c_star\": float(c_star),\n",
    "            \"theta\": theta,\n",
    "            \"eta\": eta_k,\n",
    "            \"q_before\": float(q_before),\n",
    "            \"q_after\": float(q_after),\n",
    "            \"params\": self.q_net.params_vector(),\n",
    "        })\n",
    "\n",
    "    def perform_attack(self):\n",
    "        target_queue = self.get_shortest_queue()\n",
    "        if target_queue is None or target_queue == self.server.current_queue:\n",
    "            return\n",
    "        if self.server.current_job_id is not None:\n",
    "            self.queues[self.server.current_queue].queue.appendleft(\n",
    "                (self.server.current_job_id, self.server.current_job_arrival_time)\n",
    "            )\n",
    "        self.server.update_utilization(self.current_time)\n",
    "        self.server.state = 'switching'\n",
    "        self.server.last_state_change_time = self.current_time\n",
    "        self.server.current_job_id = None\n",
    "        self.server.current_job_arrival_time = None\n",
    "        self.schedule_switch_completion(target_queue)\n",
    "\n",
    "    def process_arrival(self, queue_id):\n",
    "        queue = self.queues[queue_id]\n",
    "        queue.update_queue_stats(self.current_time)\n",
    "        job_id = queue.add_job(self.current_time)\n",
    "        self.job_counter += 1\n",
    "        self.schedule_arrival(queue_id)\n",
    "        if self.server.state == 'idle':\n",
    "            self.start_next_service()\n",
    "\n",
    "    def process_service_completion(self, queue_id, job_id):\n",
    "        if self.server.current_job_id != job_id:\n",
    "            return\n",
    "        queue = self.queues[queue_id]\n",
    "        queue.update_queue_stats(self.current_time)\n",
    "        job_id, wait_time, arrival_time = queue.process_job(self.current_time)\n",
    "        self.server.update_utilization(self.current_time)\n",
    "        if job_id is not None:\n",
    "            self.server.state = 'idle'\n",
    "            self.server.current_job_id = None\n",
    "            self.server.current_job_arrival_time = None\n",
    "        self.start_next_service()\n",
    "\n",
    "    def process_switch_completion(self, queue_id):\n",
    "        self.server.update_utilization(self.current_time)\n",
    "        self.server.state = 'idle'\n",
    "        self.server.current_queue = queue_id\n",
    "        self.start_next_service()\n",
    "\n",
    "    def start_next_service(self):\n",
    "        next_queue = self.get_longest_queue()\n",
    "        if next_queue is None:\n",
    "            self.server.state = 'idle'\n",
    "            self.server.current_queue = None\n",
    "            self.server.current_job_id = None\n",
    "            self.server.current_job_arrival_time = None\n",
    "            return\n",
    "        queue = self.queues[next_queue]\n",
    "        job_id, wait_time, arrival_time = queue.process_job(self.current_time)\n",
    "        if job_id is None:\n",
    "            self.server.state = 'idle'\n",
    "            self.server.current_queue = None\n",
    "            self.server.current_job_id = None\n",
    "            self.server.current_job_arrival_time = None\n",
    "            return\n",
    "        self.server.update_utilization(self.current_time)\n",
    "        self.server.state = 'serving'\n",
    "        self.server.current_queue = next_queue\n",
    "        self.server.current_job_id = job_id\n",
    "        self.server.current_job_arrival_time = arrival_time\n",
    "        self.schedule_service_completion(next_queue)\n",
    "\n",
    "    def print_statistics(self):\n",
    "        print(\"Simulation finished at time:\", self.current_time)\n",
    "        total_completed = sum(q.completed_jobs for q in self.queues)\n",
    "        print(\"Total completed jobs:\", total_completed)\n",
    "        for i, queue in enumerate(self.queues):\n",
    "            avg_wait = (queue.total_wait_time / queue.completed_jobs) if queue.completed_jobs > 0 else 0\n",
    "            avg_queue_length = (queue.total_queue_length_time / self.current_time) if self.current_time > 0 else 0\n",
    "            print(f\"Queue {i}:\")\n",
    "            print(\"  Completed jobs:\", queue.completed_jobs)\n",
    "            print(\"  Average wait time:\", avg_wait)\n",
    "            print(\"  Average queue length:\", avg_queue_length)\n",
    "        util = (self.server.total_busy_time / self.current_time) if self.current_time > 0 else 0\n",
    "        print(\"Server utilization:\", util)\n",
    "    \n",
    "    def plot_w_evolution(self, max_dims=10, max_steps=10000):\n",
    "        \"\"\"\n",
    "        绘制 Q 网络参数的演化曲线，显示每个分量与收敛值的差的绝对值。\n",
    "        只使用前 max_steps 次更新（如果实际更新步数不足，则使用全部）。\n",
    "        \"\"\"\n",
    "        if not self.rl_history:\n",
    "            print(\"No RL updates recorded.\")\n",
    "            return\n",
    "\n",
    "        total_steps = len(self.rl_history)\n",
    "        use_steps = min(max_steps, total_steps)\n",
    "\n",
    "        # 0, 1, ..., use_steps-1\n",
    "        steps = np.arange(use_steps)\n",
    "        param_mat = np.array([self.rl_history[i][\"params\"] for i in range(use_steps)])\n",
    "\n",
    "        # 计算与收敛值的差的绝对值\n",
    "        final_params = param_mat[-1]  # 最后一个参数值（收敛值）\n",
    "        diff_param_mat = np.abs(param_mat - final_params)  # 与收敛值的差的绝对值\n",
    "\n",
    "        # 图 1：||theta||_2 的差值\n",
    "        norms = np.linalg.norm(diff_param_mat, axis=1)\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(steps, norms)\n",
    "        plt.xlabel(\"Update step\")\n",
    "        plt.ylabel(\"||theta - theta_final||_2\")\n",
    "        plt.title(f\"Norm of Q-network parameters difference (first {use_steps} steps)\")\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # 图 2：前若干维分量的差值\n",
    "        d = diff_param_mat.shape[1]\n",
    "        dims = min(max_dims, d)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for i in range(dims):\n",
    "            plt.plot(steps, diff_param_mat[:, i], label=f\"theta[{i}] difference\")\n",
    "        plt.xlabel(\"Update step\")\n",
    "        plt.ylabel(\"Difference of theta components\")\n",
    "        plt.title(f\"First {dims} components of parameters difference (first {use_steps} steps)\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    queue_nums = 3\n",
    "    arrival_rates = [5.0, 5.0, 5.0]\n",
    "    ini_jobs_list = [0, 20, 18]\n",
    "    service_rate = 25.0\n",
    "    switch_time = 2.0\n",
    "    simulation_time = 10000.0\n",
    "\n",
    "    system = PollingSystem(\n",
    "        queue_nums=queue_nums,\n",
    "        arrival_rates=arrival_rates,\n",
    "        ini_jobs_list=ini_jobs_list,\n",
    "        service_rate=service_rate,\n",
    "        switch_time=switch_time,\n",
    "        simulation_time=simulation_time,\n",
    "    )\n",
    "\n",
    "    system.run_simulation()\n",
    "    system.print_statistics()\n",
    "\n",
    "    final_state = [len(q.queue) for q in system.queues]\n",
    "    print(\"\\nFinal Q-network parameter norm:\")\n",
    "    print(np.linalg.norm(system.q_net.params_vector()))\n",
    "    print(\"Final state (queue lengths):\", final_state)\n",
    "    for a in (0, 1):\n",
    "        for b in (0, 1):\n",
    "            q_val = system.q_value(final_state, a, b)\n",
    "            print(f\"Q(X_final, a={a}, b={b}) = {q_val:.4f}\")\n",
    "\n",
    "    if len(system.rl_history) > 0:\n",
    "        print(\"\\nLast 5 updates:\")\n",
    "        for rec in system.rl_history[-5:]:\n",
    "            print(f\"time={rec['time']:.2f}, delta={rec['delta_clipped']}, q_before={rec['q_before']}, q_after={rec['q_after']}\")\n",
    "            print(\"param_norm:\", np.linalg.norm(rec[\"params\"]))\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "    system.plot_w_evolution(max_dims=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16769bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_130340\\1865226673.py:105: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  out = float(h2 @ self.W3 + self.b3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation finished at time: 9999.972881225436\n",
      "Total completed jobs: 149880\n",
      "Queue 0:\n",
      "  Completed jobs: 49812\n",
      "  Average wait time: 0.5575476277031185\n",
      "  Average queue length: 2.8197302818008203\n",
      "Queue 1:\n",
      "  Completed jobs: 50203\n",
      "  Average wait time: 0.5699569449639634\n",
      "  Average queue length: 2.8636682920475716\n",
      "Queue 2:\n",
      "  Completed jobs: 49865\n",
      "  Average wait time: 0.5816271182627175\n",
      "  Average queue length: 2.8750754563258223\n",
      "Server utilization: 0.49718766254978974\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class PollingSystemWithNN(PollingSystem):\n",
    "    def __init__(self, queue_nums, arrival_rates, ini_jobs_list, service_rate, switch_time, simulation_time, q_net):\n",
    "        \"\"\"\n",
    "        初始化时，除了基本的仿真参数外，还传入外部神经网络 (q_net)。\n",
    "        \"\"\"\n",
    "        super().__init__(queue_nums, arrival_rates, ini_jobs_list, service_rate, switch_time, simulation_time)\n",
    "        self.q_net = q_net  # 接收外部传入的神经网络\n",
    "\n",
    "    def run_simulation_with_nn(self):\n",
    "        \"\"\"\n",
    "        运行仿真过程，神经网络用于决策（进攻、防守）。\n",
    "        保留训练过程的历史记录（rl_history）。\n",
    "        \"\"\"\n",
    "        while self.event_queue:\n",
    "            event = heapq.heappop(self.event_queue)\n",
    "            self.current_time = event.time\n",
    "\n",
    "            # 检查是否超过仿真时间，结束仿真\n",
    "            if self.current_time > self.simulation_time:\n",
    "                break\n",
    "\n",
    "            # 根据事件类型处理不同的事件\n",
    "            if event.event_type == 'arrival':\n",
    "                self.process_arrival(event.queue_id)\n",
    "            elif event.event_type == 'service_completion':\n",
    "                self.process_service_completion(event.queue_id, event.job_id)\n",
    "                self.maybe_attack_defend_with_nn()\n",
    "            elif event.event_type == 'switch_completion':\n",
    "                self.process_switch_completion(event.queue_id)\n",
    "\n",
    "        # 更新队列的统计信息\n",
    "        for queue in self.queues:\n",
    "            queue.update_queue_stats(self.simulation_time)\n",
    "        self.server.update_utilization(self.simulation_time)\n",
    "\n",
    "    def maybe_attack_defend_with_nn(self):\n",
    "        \"\"\"\n",
    "        使用传入的神经网络进行决策（进攻或防守）。\n",
    "        记录强化学习历史（rl_history）。\n",
    "        \"\"\"\n",
    "        X_k = [len(q.queue) for q in self.queues]  # 当前队列长度作为状态\n",
    "        a, b = self.sample_actions_from_nn(X_k)  # 使用神经网络来选择进攻或防守动作\n",
    "\n",
    "        attack_success = (a == 1 and b == 0 and self.server.state == 'serving')\n",
    "\n",
    "        # 计算奖励（奖励函数可以根据实际情况设计，这里假设我们使用了原有的奖励计算方法）\n",
    "        R_k1 = self.compute_reward(X_k, a, b, ns=1.0)\n",
    "\n",
    "        if attack_success:\n",
    "            self.perform_attack()\n",
    "\n",
    "        # 计算下一状态 X_k1\n",
    "        X_k1 = [len(q.queue) for q in self.queues]\n",
    "\n",
    "        # 计算Q值并进行参数更新\n",
    "        Q_next = {(aa, bb): self.q_value(X_k1, aa, bb) for aa in (0, 1) for bb in (0, 1)}\n",
    "        c_star, theta = self.solve_theta_minimax(Q_next)\n",
    "\n",
    "        q_curr = self.q_value(X_k, a, b)\n",
    "        raw_target = R_k1 + self.gamma * c_star\n",
    "        delta_raw = raw_target - q_curr\n",
    "        delta_k = float(np.clip(delta_raw, -self.delta_clip, self.delta_clip))\n",
    "        target = q_curr + delta_k\n",
    "\n",
    "        phi = self.features(X_k, a, b)\n",
    "\n",
    "        # 更新神经网络\n",
    "        self.step_counter += 1\n",
    "        K = 50000.0\n",
    "        eta_k = self.eta0 / (1.0 + self.step_counter / K)\n",
    "\n",
    "        # 每隔一定步数进行训练\n",
    "        if (self.step_counter % self.train_interval) == 0:\n",
    "            _, q_before = self.q_net.train(phi, target, eta=eta_k, clip=self.step_clip)\n",
    "            q_after = self.q_net.predict(phi)\n",
    "        else:\n",
    "            q_before = q_after = q_curr\n",
    "\n",
    "        # 保存RL训练过程中的数据\n",
    "        self.rl_history.append({\n",
    "            \"time\": self.current_time,\n",
    "            \"X_k\": X_k,\n",
    "            \"a\": a,\n",
    "            \"b\": b,\n",
    "            \"X_k1\": X_k1,\n",
    "            \"R_k1\": R_k1,\n",
    "            \"delta_raw\": float(delta_raw),\n",
    "            \"delta_clipped\": float(delta_k),\n",
    "            \"c_star\": float(c_star),\n",
    "            \"theta\": theta,\n",
    "            \"eta\": eta_k,\n",
    "            \"q_before\": float(q_before),\n",
    "            \"q_after\": float(q_after),\n",
    "            \"params\": self.q_net.params_vector(),\n",
    "        })\n",
    "\n",
    "    def sample_actions_from_nn(self, X):\n",
    "        \"\"\"\n",
    "        ???????????????? X ?????a?????b????\n",
    "        \"\"\"\n",
    "        q_values = []\n",
    "        for a in (0, 1):\n",
    "            for b in (0, 1):\n",
    "                phi = self.features(X, a, b)\n",
    "                q_values.append(self.q_net.predict(phi))\n",
    "\n",
    "        # ??Q??????\n",
    "        best_action = int(np.argmax(q_values))\n",
    "        a, b = divmod(best_action, 2)  # ???????? (a, b) ?????\n",
    "        return a, b\n",
    "\n",
    "\n",
    "\n",
    "        # 选择Q值最大的动作\n",
    "        best_action = np.argmax(q_values)\n",
    "        a, b = divmod(best_action, 2)  # 将一维动作映射回 (a, b) 对应的动作\n",
    "        return a, b\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    q_net = system.q_net\n",
    "\n",
    "    # 初始化仿真系统，并传入神经网络\n",
    "    system_with_nn = PollingSystemWithNN(\n",
    "        queue_nums=3,\n",
    "        arrival_rates=[5.0, 5.0, 5.0],\n",
    "        ini_jobs_list=[0, 20, 18],\n",
    "        service_rate=25.0,\n",
    "        switch_time=2.0,\n",
    "        simulation_time=10000.0,\n",
    "        q_net=q_net  # 传入神经网络\n",
    "    )\n",
    "\n",
    "    # 运行仿真\n",
    "    system_with_nn.run_simulation_with_nn()\n",
    "\n",
    "    # 输出仿真结果\n",
    "    system_with_nn.print_statistics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
